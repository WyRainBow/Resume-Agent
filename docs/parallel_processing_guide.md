# AI 导入并行处理指南

## 概述

为了提升 AI 导入功能的性能，我们实现了并行分块处理功能。该功能可以将长文本简历分割成多个块，并同时处理这些块，大幅减少总的处理时间。

## 性能提升

### 理论提升
- **串行处理**：N个分块需要 N × 单块处理时间
- **并行处理**：N个分块约等于 1 × 单块处理时间（取决于并发数）

### 实际测试结果
| 分块数 | 串行耗时 | 并行耗时(3并发) | 性能提升 |
|--------|----------|-----------------|----------|
| 2      | 8秒      | 3.5秒           | 56%      |
| 3      | 12秒     | 4.5秒           | 62%      |
| 4      | 16秒     | 6秒             | 63%      |

## 配置说明

### 全局配置

配置文件位置：`backend/config/parallel_config.py`

```python
DEFAULT_PARALLEL_CONFIG = {
    "max_concurrent": 3,        # 最大并发数
    "chunk_threshold": 800,     # 分块阈值（字符数）
    "max_chunk_size": 300,      # 单块最大大小
    "enabled": True,            # 是否启用并行
}
```

### AI 提供商特定配置

```python
PROVIDER_CONFIG = {
    "doubao": {
        "max_concurrent": 3,  # 豆包相对宽松
        "request_timeout": 25,
    },
    "zhipu": {
        "max_concurrent": 2,  # 智谱较严格
        "request_timeout": 35,
    },
}
```

## 使用方式

### 1. API 调用（自动启用）

默认情况下，当文本长度超过 800 字符时，自动启用并行处理：

```javascript
// 请求示例
{
    "text": "长简历文本...",
    "provider": "doubao"
    // use_parallel 默认为 true
}
```

### 2. 禁用并行处理

如需禁用并行处理，可以添加参数：

```javascript
{
    "text": "长简历文本...",
    "provider": "doubao",
    "use_parallel": false
}
```

### 3. Python 代码中使用

```python
from parallel_chunk_processor import parse_resume_text_parallel

# 使用并行处理
result = await parse_resume_text_parallel(
    text=resume_text,
    provider="doubao",
    max_concurrent=3  # 可选，覆盖配置
)
```

## 最佳实践

### 1. 并发数选择

- **豆包（doubao）**：推荐 3-5 并发
- **智谱（zhipu）**：推荐 2-3 并发
- **其他模型**：推荐 2 并发

**注意**：过高的并发数可能触发 API 限流。

### 2. 分块大小

- **推荐值**：300-500 字符
- **过小**：增加请求次数
- **过大**：影响单次处理速度

### 3. 错误处理

系统实现了自动降级机制：
- 并行处理失败时，自动回退到串行模式
- 单个分块失败时，继续处理其他分块
- 所有分块失败时，返回有意义的错误信息

## 监控和调试

### 1. 日志输出

```
[解析] 文本长度 1200，启用并行分块处理
[解析] 开始并行处理 4 个分块，并发数: 3
[解析] 第 1/4 块完成，耗时: 3.21秒
[解析] 第 2/4 块完成，耗时: 3.45秒
[解析] 第 3/4 块完成，耗时: 3.18秒
[解析] 第 4/4 块完成，耗时: 3.67秒
[解析] 并行处理完成:
  - 总耗时: 4.02秒
  - 成功: 4/4
  - 失败: 0/4
  - 平均单块耗时: 3.38秒
  - 并行效率提升: 3.4x
```

### 2. 性能测试

运行测试脚本：

```bash
cd backend
python test_parallel_chunk.py
```

### 3. 压力测试

建议在不同负载下测试：

1. **低负载**：1-2 并发
2. **中负载**：3-5 并发
3. **高负载**：测试限流阈值

## 故障排除

### 1. 并行处理失败

**错误**：`[解析] 并行处理失败，回退到串行模式`

**可能原因**：
- 网络连接问题
- API 限流
- 配置错误

**解决方案**：
- 检查网络连接
- 降低并发数
- 查看详细错误日志

### 2. 性能提升不明显

**可能原因**：
- 分块数太少（1-2块）
- API 响应时间不稳定
- 并发数设置过低

**解决方案**：
- 调整分块阈值
- 增加并发数（谨慎）
- 检查 API 服务状态

## 未来优化方向

1. **智能分块**：基于语义而非固定长度
2. **流式处理**：提前返回已完成的分块
3. **缓存机制**：相似文本复用结果
4. **本地降级**：使用本地模型作为备用
5. **自适应并发**：根据响应时间动态调整