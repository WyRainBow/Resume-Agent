# AI 简历导入 Agent 集成技术方案

## 一、目标

将 AI 简历导入功能升级为具备**推理-执行-反思-修正**完整闭环的 Agent 系统，通过引入 Chain-of-Thought（链式思考）和 Reflection（反思）机制，让大语言模型能够：
- 自主推理解析步骤
- 执行结构化提取
- 反思结果准确性
- 自动修正错误和遗漏

## 二、总体架构

### 2.1 核心组件

```
┌─────────────────────────────────────────────────────────┐
│              Orchestrator (调度器)                        │
│  - 接收解析请求                                          │
│  - 任务拆分与策略选择                                    │
│  - 执行流程编排                                          │
│  - 状态管理与日志记录                                    │
└─────────────────────────────────────────────────────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
        ▼               ▼               ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│   Planner    │ │   Reasoner   │ │  Reflection  │
│  (规划器)    │ │  (推理器)     │ │  (反思器)     │
└──────────────┘ └──────────────┘ └──────────────┘
        │               │               │
        └───────────────┼───────────────┘
                        │
                        ▼
              ┌──────────────────┐
              │ Validator &       │
              │ Normalizer        │
              │ (校验与规范化)    │
              └──────────────────┘
```

### 2.2 组件详细说明

#### 1. **Orchestrator（调度器）**
- **职责**：整个解析流程的编排者
- **功能**：
  - 接收前端解析请求
  - 根据文本长度和复杂度选择执行策略
  - 管理整个解析流程的状态
  - 记录执行日志和性能指标
  - 处理错误和降级策略

#### 2. **Planner（规划器）** - 可选组件
- **职责**：生成解析计划
- **功能**：
  - 分析输入文本结构
  - 生成解析步骤清单
  - 确定解析优先级
- **实现方式**：
  - 轻量级：在系统 prompt 中让 LLM 先列出步骤，再执行
  - 完整版：独立的规划 Agent，生成结构化计划

#### 3. **Reasoner（推理器）**
- **职责**：执行主要解析任务
- **功能**：
  - 使用 Chain-of-Thought 进行推理
  - 提取结构化信息
  - 生成符合 schema 的 JSON
- **特点**：
  - 支持单轮推理（短文本）
  - 支持多轮推理（复杂场景）

#### 4. **Reflection Agent（反思器）**
- **职责**：反思和修正解析结果
- **功能**：
  - 对比原文和解析结果
  - 识别遗漏和错误
  - 生成修正建议
  - 执行修正操作
- **输入**：
  - 原始文本
  - 当前解析结果
  - （可选）截图或差异分析
- **输出**：
  - 修正后的 JSON
  - 修正说明
  - 置信度评估

#### 5. **Validator & Normalizer（校验与规范化）**
- **职责**：数据校验和格式规范化
- **功能**：
  - 字段完整性校验
  - 格式规范校验
  - 数据清洗和标准化
  - 合并分块结果

#### 6. **Chunk Processor（分块处理器）**
- **职责**：处理长文本分块
- **功能**：
  - 智能分块（按模块、按段落）
  - 并行处理多个分块
  - 合并分块结果
  - 处理分块边界问题

## 三、核心流程设计

### 3.1 全局解析流程

```
开始
  │
  ▼
接收文本输入
  │
  ▼
判断文本长度
  │
  ├─→ 短文本（< 800字符）
  │     │
  │     ▼
  │   Planner 生成解析计划（可选）
  │     │
  │     ▼
  │   Reasoner 执行推理解析
  │     │
  │     ▼
  │   Validator 校验结果
  │     │
  │     ▼
  │   Reflection Agent 反思修正
  │     │
  │     ▼
  │   Normalizer 规范化
  │     │
  │     ▼
  │   返回结果
  │
  └─→ 长文本（≥ 800字符）
        │
        ▼
      Chunk Processor 分块
        │
        ▼
      并行执行各分块解析
        │
        ▼
      合并分块结果
        │
        ▼
      Validator 全局校验
        │
        ▼
      Reflection Agent 全局反思
        │
        ▼
      Normalizer 规范化
        │
        ▼
      返回结果
```

### 3.2 Reflection 流程

```
开始 Reflection
  │
  ▼
输入：原文 + 当前 JSON
  │
  ▼
LLM 分析对比
  │
  ├─→ 发现遗漏/错误
  │     │
  │     ▼
  │   生成修正建议
  │     │
  │     ▼
  │   执行修正
  │     │
  │     ▼
  │   返回修正后 JSON
  │
  └─→ 未发现问题
        │
        ▼
      返回原 JSON + 确认信息
```

### 3.3 多轮 Reflection 机制

```
第一轮 Reflection
  │
  ▼
检查结果质量
  │
  ├─→ 质量不达标
  │     │
  │     ▼
  │   第二轮 Reflection（可选）
  │     │
  │     ├─→ 成功修正
  │     │     │
  │     │     ▼
  │     │   返回修正结果
  │     │
  │     └─→ 仍失败
  │           │
  │           ▼
  │         返回原结果 + 警告
  │
  └─→ 质量达标
        │
        ▼
      返回结果
```

## 四、Prompt 设计

### 4.1 Planner Prompt（规划阶段）

```
你是一个专业的简历解析规划助手。

任务：分析以下简历文本，生成一个解析计划。

要求：
1. 识别文本中包含的模块（教育、工作、项目、技能等）
2. 列出解析步骤
3. 标注每个步骤的优先级
4. 识别可能的难点和注意事项

简历文本：
{text}

请以 JSON 格式输出解析计划：
{
  "modules": ["教育经历", "项目经历", ...],
  "steps": [
    {"step": 1, "action": "提取教育经历", "priority": "high"},
    ...
  ],
  "challenges": ["可能的难点说明"]
}
```

### 4.2 Reasoner Prompt（推理阶段）

```
你是一个专业的简历解析助手。请使用 Chain-of-Thought 方式思考，然后提取信息。

思考过程：
1. 首先分析文本结构
2. 识别各个模块
3. 提取关键信息
4. 验证信息完整性

简历文本：
{text}

请按照以下步骤思考并输出：
步骤1：分析文本结构
步骤2：识别模块
步骤3：提取信息
步骤4：验证完整性

最终输出 JSON（严格按照 schema）：
{schema_desc}
```

### 4.3 Reflection Prompt（反思阶段）

```
你是一个专业的简历解析质量检查助手。

任务：对比原始文本和解析结果，找出遗漏、错误或不一致的地方，并生成修正后的结果。

原始文本：
{original_text}

当前解析结果：
{current_json}

请执行以下步骤：
1. 逐项对比原始文本和解析结果
2. 识别遗漏的信息
3. 识别错误的信息
4. 识别格式问题
5. 生成修正后的完整 JSON

如果发现问题，请输出：
{
  "has_issues": true,
  "issues": [
    {"type": "missing", "field": "projects[0].description", "description": "遗漏了项目描述"},
    ...
  ],
  "corrected_json": {修正后的完整 JSON}
}

如果未发现问题，请输出：
{
  "has_issues": false,
  "confidence": 0.95,
  "message": "解析结果完整准确"
}
```

### 4.4 分块解析 Prompt

```
从简历文本片段提取信息，只输出 JSON（不要 markdown，无数据的字段用空数组[]）。

重要提示：
1. 这是文本的第 {chunk_index}/{total_chunks} 块
2. 片段所属模块：{section}
3. 请标注提取的信息来源（便于后续合并）

片段内容：
{chunk_content}

{schema_desc}
```

## 五、数据结构设计

### 5.1 请求结构

```typescript
interface AgentParseRequest {
  text: string                    // 简历文本
  provider?: string               // AI 提供商
  use_parallel?: boolean         // 是否使用并行处理
  use_reflection?: boolean       // 是否启用反思机制
  reflection_rounds?: number     // 反思轮数（默认 1）
  enable_planning?: boolean      // 是否启用规划阶段
}
```

### 5.2 响应结构

```typescript
interface AgentParseResponse {
  resume: ResumeData              // 解析后的简历数据
  method: string                 // 使用的解析方法
  reflection_used: boolean       // 是否使用了反思
  reflection_rounds?: number     // 实际反思轮数
  warnings?: string[]            // 警告信息
  confidence?: number            // 置信度（0-1）
  trace_id?: string              // 追踪 ID（用于调试）
}
```

### 5.3 内部执行状态

```python
class ParseExecutionState:
    trace_id: str
    start_time: float
    stages: List[StageInfo]
    errors: List[ErrorInfo]
    performance_metrics: Dict[str, float]

class StageInfo:
    name: str                    # 阶段名称（planning/reasoning/reflection）
    start_time: float
    end_time: float
    input_tokens: int
    output_tokens: int
    success: bool
    error: Optional[str]
```

## 六、失败与降级策略

### 6.1 多层级降级

```
Level 1: Agent 完整流程（Reasoning + Reflection）
    │
    ├─→ 失败
    │     │
    │     ▼
Level 2: 简化 Agent（仅 Reasoning，无 Reflection）
    │
    ├─→ 失败
    │     │
    │     ▼
Level 3: 智能解析（Smart Parse，基于规则）
    │
    ├─→ 失败
    │     │
    │     ▼
Level 4: 正则提取（Regex Extract）
    │
    ├─→ 失败
    │     │
    │     ▼
Level 5: JSON Repair（尝试修复）
    │
    └─→ 最终失败：返回错误信息
```

### 6.2 错误处理策略

1. **LLM 调用失败**
   - 自动重试（最多 3 次）
   - 切换备用 provider
   - 降级到规则解析

2. **JSON 解析失败**
   - 尝试 JSON Repair
   - 尝试正则提取 JSON 片段
   - 返回部分结果 + 警告

3. **Reflection 失败**
   - 记录失败原因
   - 返回未修正的结果
   - 添加警告信息

4. **分块合并冲突**
   - 使用合并策略（覆盖/合并/智能选择）
   - 记录冲突字段
   - 触发全局 Reflection 修正

## 七、性能优化

### 7.1 并行处理优化

- **分块并行**：多个分块同时处理
- **Reflection 并行**：多轮反思可以并行执行（如果独立）
- **缓存机制**：相同文本的解析结果可以缓存

### 7.2 成本控制

- **Token 限制**：设置最大 token 数
- **超时控制**：每个阶段设置超时时间
- **Provider 切换**：根据成本选择 provider
- **批量处理**：多个请求可以批量处理

### 7.3 响应时间优化

- **流式输出**：支持流式返回部分结果
- **异步处理**：长时间任务异步执行
- **结果缓存**：缓存常见解析结果

## 八、安全与隐私

### 8.1 数据安全

- **敏感信息脱敏**：日志中脱敏电话、邮箱等
- **数据加密**：传输和存储加密
- **访问控制**：限制 API 访问频率

### 8.2 隐私保护

- **数据保留策略**：解析结果不长期存储
- **用户授权**：明确告知数据使用方式
- **数据删除**：支持用户删除数据

## 九、监控与调试

### 9.1 日志记录

- **结构化日志**：记录每个阶段的详细信息
- **性能指标**：记录响应时间、token 使用量
- **错误追踪**：记录错误堆栈和上下文

### 9.2 调试工具

- **Trace ID**：每个请求分配唯一 ID
- **调试模式**：可以输出中间结果
- **可视化工具**：展示解析流程和结果

### 9.3 监控指标

- **成功率**：解析成功率
- **响应时间**：平均响应时间
- **错误率**：各阶段错误率
- **成本统计**：Token 使用量和成本

## 十、实施路线图

### Phase 1: 基础 Agent 框架（v0.1）
- [ ] 实现 Orchestrator 基础功能
- [ ] 实现 Reasoner（带 CoT）
- [ ] 实现基础 Validator
- [ ] 集成到现有解析流程

### Phase 2: Reflection 机制（v0.2）
- [ ] 实现 Reflection Agent
- [ ] 实现多轮反思机制
- [ ] 优化 Reflection Prompt
- [ ] 测试和调优

### Phase 3: 规划器集成（v0.3）
- [ ] 实现轻量级 Planner
- [ ] 集成规划-推理-反思完整流程
- [ ] 性能优化

### Phase 4: 高级特性（v0.4）
- [ ] 智能分块策略
- [ ] 并行 Reflection
- [ ] 缓存机制
- [ ] 流式输出

### Phase 5: 生产优化（v1.0）
- [ ] 完整监控体系
- [ ] 性能调优
- [ ] 安全加固
- [ ] 文档完善

## 十一、技术选型建议

### 11.1 LLM Provider
- **主选**：DeepSeek（成本低、性能好）
- **备选**：OpenAI GPT-4、Claude
- **策略**：支持多 provider 切换

### 11.2 框架选择
- **Agent 框架**：LangChain / LlamaIndex（可选）
- **异步处理**：Python asyncio
- **任务队列**：Celery（如需要）

### 11.3 存储方案
- **缓存**：Redis
- **日志**：文件系统 + 可选 ELK
- **监控**：Prometheus + Grafana（可选）

## 十二、风险评估

### 12.1 技术风险
- **LLM 不稳定**：通过降级策略缓解
- **成本过高**：通过 token 限制和缓存控制
- **响应时间过长**：通过并行和异步优化

### 12.2 业务风险
- **解析准确率下降**：通过 Reflection 机制保障
- **用户体验差**：通过流式输出和进度提示改善

## 十三、成功指标

### 13.1 准确性指标
- **字段完整率**：> 95%
- **信息准确率**：> 90%
- **格式正确率**：> 98%

### 13.2 性能指标
- **平均响应时间**：< 5 秒（短文本），< 15 秒（长文本）
- **成功率**：> 95%
- **错误率**：< 5%

### 13.3 成本指标
- **单次解析成本**：< $0.01（短文本），< $0.05（长文本）
- **Token 使用量**：控制在合理范围

## 十四、总结

本方案通过引入 Agent 架构和 Reflection 机制，将简历解析从简单的 prompt 调用升级为具备推理和自修正能力的智能系统。通过分阶段实施，可以逐步提升解析质量和用户体验，同时控制成本和风险。

关键优势：
1. **更高的准确性**：通过推理和反思机制提升解析质量
2. **更好的可解释性**：每个步骤都有清晰的逻辑
3. **更强的鲁棒性**：多层级降级策略保障可用性
4. **更好的扩展性**：模块化设计便于后续扩展

