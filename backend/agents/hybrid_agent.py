"""
HybridAgent - æ··åˆæ¨¡å¼ Agent

æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹©æ‰§è¡Œæ¨¡å¼ï¼š
- ç®€å•ä»»åŠ¡ â†’ Function Callingï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
- å¤æ‚ä»»åŠ¡ â†’ ReActï¼ˆæ¨ç†è·¯å¾„ï¼‰

æ¶æ„ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           HybridAgent (ç»Ÿä¸€å…¥å£)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  TaskClassifier                   â”‚  â”‚
â”‚  â”‚  æ ¹æ®ä»»åŠ¡ç‰¹å¾é€‰æ‹©æ‰§è¡Œæ¨¡å¼ï¼š         â”‚  â”‚
â”‚  â”‚  - ç®€å•ä»»åŠ¡ â†’ Function Calling    â”‚  â”‚
â”‚  â”‚  - å¤æ‚ä»»åŠ¡ â†’ ReAct               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚
    â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FC     â”‚  â”‚  ReAct   â”‚
â”‚  Agent  â”‚  â”‚  Agent   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚            â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ToolRegistry â”‚
    â”‚  (ç»Ÿä¸€å·¥å…·)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import json
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, AsyncGenerator, Callable, Dict, Generator, List, Optional

from .task_classifier import TaskClassifier, ClassificationResult, ExecutionMode, TaskComplexity
from .capability import Capability, CapabilityRegistry, BASE_CAPABILITY
from .agent_state import AgentState
from .message_builder import MessageBuilder, MessageType, AgentMessage


@dataclass
class HybridAgentConfig:
    """æ··åˆ Agent é…ç½®"""
    # æ‰§è¡Œæ¨¡å¼é€‰æ‹©
    mode: ExecutionMode = ExecutionMode.AUTO

    # Function Calling é…ç½®
    enable_function_calling: bool = True
    fc_temperature: float = 0.1

    # ReAct é…ç½®
    enable_react: bool = True
    react_max_steps: int = 10
    react_temperature: float = 0.3

    # è‡ªåŠ¨é€‰æ‹©é˜ˆå€¼
    simple_task_max_length: int = 50
    complex_task_min_length: int = 150

    # è°ƒè¯•
    debug: bool = False
    log_mode_selection: bool = True


@dataclass
class ExecutionContext:
    """æ‰§è¡Œä¸Šä¸‹æ–‡"""
    session_id: str
    user_message: str
    classification: ClassificationResult
    start_time: float = field(default_factory=time.time)
    steps: List[Dict] = field(default_factory=list)
    tool_calls: List[Dict] = field(default_factory=list)

    @property
    def duration_ms(self) -> int:
        return int((time.time() - self.start_time) * 1000)


class HybridAgent:
    """
    æ··åˆæ¨¡å¼ Agent

    æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨é€‰æ‹© Function Calling æˆ– ReAct æ¨¡å¼ã€‚
    """

    def __init__(
        self,
        resume_data: Optional[Dict[str, Any]] = None,
        session_id: str = "",
        capability: Optional[Capability] = None,
        config: Optional[HybridAgentConfig] = None,
        llm_call_fn: Optional[Callable] = None,
    ):
        """
        åˆå§‹åŒ–æ··åˆ Agent

        Args:
            resume_data: ç®€å†æ•°æ®
            session_id: ä¼šè¯ ID
            capability: èƒ½åŠ›åŒ…é…ç½®
            config: æ··åˆ Agent é…ç½®
            llm_call_fn: LLM è°ƒç”¨å‡½æ•°ï¼ˆç­¾åä¸º call_llm(messages, tools) -> dictï¼‰
        """
        self.resume_data = resume_data or {}
        self.session_id = session_id
        self.capability = capability or BASE_CAPABILITY
        self.config = config or HybridAgentConfig()
        self.llm_call_fn = llm_call_fn

        # çŠ¶æ€ç®¡ç†
        self.state = AgentState(resume_data=resume_data, session_id=session_id)
        self.chat_history: List[Dict[str, str]] = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_requests": 0,
            "function_calling_count": 0,
            "react_count": 0,
            "mode_selections": [],
        }

    # ========== æ ¸å¿ƒå¤„ç†æ–¹æ³• ==========

    def process_message(self, user_message: str) -> AgentMessage:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆéæµå¼ï¼‰

        Args:
            user_message: ç”¨æˆ·è¾“å…¥

        Returns:
            Agent æ¶ˆæ¯
        """
        # åˆ†ç±»ä»»åŠ¡
        classification = self._classify_task(user_message)

        # è®°å½•ç»Ÿè®¡
        self.stats["total_requests"] += 1
        self.stats["mode_selections"].append({
            "mode": classification.mode.value,
            "complexity": classification.complexity.value,
            "confidence": classification.confidence,
            "reason": classification.reason,
        })

        # æ·»åŠ åˆ°å†å²
        self.state.add_message("user", user_message)

        # æ ¹æ®æ¨¡å¼æ‰§è¡Œ
        if classification.mode == ExecutionMode.REACT:
            self.stats["react_count"] += 1
            return self._process_with_react(user_message, classification)
        else:
            self.stats["function_calling_count"] += 1
            return self._process_with_function_calling(user_message, classification)

    def process_message_stream(self, user_message: str) -> Generator[Dict[str, Any], None, None]:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆæµå¼ï¼‰

        Args:
            user_message: ç”¨æˆ·è¾“å…¥

        Yields:
            äº‹ä»¶å­—å…¸
        """
        # åˆ†ç±»ä»»åŠ¡
        classification = self._classify_task(user_message)

        # è®°å½•ç»Ÿè®¡
        self.stats["total_requests"] += 1
        self.stats["mode_selections"].append({
            "mode": classification.mode.value,
            "complexity": classification.complexity.value,
            "confidence": classification.confidence,
            "reason": classification.reason,
        })

        # æ·»åŠ åˆ°å†å²
        self.state.add_message("user", user_message)

        # å‘é€åˆ†ç±»ä¿¡æ¯
        if self.config.log_mode_selection:
            yield {
                "type": "mode_selected",
                "mode": classification.mode.value,
                "complexity": classification.complexity.value,
                "confidence": classification.confidence,
                "reason": classification.reason,
                "session_id": self.session_id,
            }

        # æ ¹æ®æ¨¡å¼æ‰§è¡Œ
        if classification.mode == ExecutionMode.REACT:
            self.stats["react_count"] += 1
            yield from self._process_stream_with_react(user_message, classification)
        else:
            self.stats["function_calling_count"] += 1
            yield from self._process_stream_with_function_calling(user_message, classification)

    # ========== åˆ†ç±»æ–¹æ³• ==========

    def _classify_task(self, user_message: str) -> ClassificationResult:
        """åˆ†ç±»ä»»åŠ¡"""
        # æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å¼ºåˆ¶æŒ‡å®šæ¨¡å¼
        if self.config.mode == ExecutionMode.FUNCTION_CALLING:
            return ClassificationResult(
                mode=ExecutionMode.FUNCTION_CALLING,
                complexity=TaskComplexity.SIMPLE,
                confidence=1.0,
                reason="é…ç½®å¼ºåˆ¶ä½¿ç”¨ Function Calling"
            )
        elif self.config.mode == ExecutionMode.REACT:
            return ClassificationResult(
                mode=ExecutionMode.REACT,
                complexity=TaskComplexity.COMPLEX,
                confidence=1.0,
                reason="é…ç½®å¼ºåˆ¶ä½¿ç”¨ ReAct"
            )

        # ä½¿ç”¨ TaskClassifier è‡ªåŠ¨åˆ†ç±»
        return TaskClassifier.classify(user_message, self.resume_data)

    # ========== Function Calling è·¯å¾„ ==========

    def _process_with_function_calling(
        self,
        user_message: str,
        classification: ClassificationResult
    ) -> AgentMessage:
        """ä½¿ç”¨ Function Calling å¤„ç†"""
        # æ·»åŠ åˆ°å†å²
        self.chat_history.append({"role": "user", "content": user_message})

        # æ„å»ºæ¶ˆæ¯
        messages = self._build_messages_for_llm(user_message)

        # è°ƒç”¨ LLM
        if self.llm_call_fn:
            response = self.llm_call_fn(
                messages=messages,
                tools=self._get_function_calling_tools(),
                temperature=self.config.fc_temperature
            )
        else:
            # æ²¡æœ‰æä¾› LLM å‡½æ•°ï¼Œè¿”å›é”™è¯¯
            return MessageBuilder.error(
                message="LLM æœªé…ç½®ï¼Œæ— æ³•å¤„ç†è¯·æ±‚",
                session_id=self.session_id
            )

        # å¤„ç†å“åº”
        if response.get("tool_calls"):
            # æœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå¹¶è¿”å›
            return self._handle_tool_calls(response, messages)
        else:
            # ç›´æ¥å›å¤
            content = response.get("content", "å¤„ç†å®Œæˆ")
            self.chat_history.append({"role": "assistant", "content": content})
            return MessageBuilder.text(content=content, session_id=self.session_id)

    def _process_stream_with_function_calling(
        self,
        user_message: str,
        classification: ClassificationResult
    ) -> Generator[Dict[str, Any], None, None]:
        """ä½¿ç”¨ Function Calling æµå¼å¤„ç†"""
        # æ·»åŠ åˆ°å†å²
        self.chat_history.append({"role": "user", "content": user_message})

        yield {
            "type": "thinking",
            "content": f"ğŸ“¥ æ¥æ”¶: {user_message[:30]}...\nğŸ”§ ä½¿ç”¨ Function Calling æ¨¡å¼",
            "session_id": self.session_id,
        }

        # æ„å»ºæ¶ˆæ¯
        messages = self._build_messages_for_llm(user_message)

        # è°ƒç”¨ LLMï¼ˆéœ€è¦æ”¯æŒæµå¼ï¼‰
        if self.llm_call_fn and hasattr(self.llm_call_fn, 'stream'):
            # æµå¼è°ƒç”¨
            accumulated_content = ""
            tool_calls = []

            for chunk in self.llm_call_fn.stream(
                messages=messages,
                tools=self._get_function_calling_tools(),
                temperature=self.config.fc_temperature
            ):
                delta = chunk.get("choices", [{}])[0].get("delta", {})

                if "content" in delta and delta["content"]:
                    accumulated_content += delta["content"]
                    yield {
                        "type": "content_chunk",
                        "content": accumulated_content,
                        "session_id": self.session_id,
                    }

                if "tool_calls" in delta:
                    # å¤„ç†å·¥å…·è°ƒç”¨...
                    pass

            # å¤„ç†æœ€ç»ˆç»“æœ
            if tool_calls:
                yield from self._handle_tool_calls_stream(tool_calls, messages, user_message)
            else:
                self.chat_history.append({"role": "assistant", "content": accumulated_content})
                yield {
                    "type": "content",
                    "content": accumulated_content,
                    "session_id": self.session_id,
                }

        elif self.llm_call_fn:
            # éæµå¼è°ƒç”¨
            response = self.llm_call_fn(
                messages=messages,
                tools=self._get_function_calling_tools(),
                temperature=self.config.fc_temperature
            )

            if response.get("tool_calls"):
                yield from self._handle_tool_calls_stream([response["tool_calls"]], messages, user_message)
            else:
                content = response.get("content", "å¤„ç†å®Œæˆ")
                self.chat_history.append({"role": "assistant", "content": content})
                yield {
                    "type": "content",
                    "content": content,
                    "session_id": self.session_id,
                }
        else:
            yield {
                "type": "error",
                "content": "LLM æœªé…ç½®",
                "session_id": self.session_id,
            }

    # ========== ReAct è·¯å¾„ ==========

    def _process_with_react(
        self,
        user_message: str,
        classification: ClassificationResult
    ) -> AgentMessage:
        """ä½¿ç”¨ ReAct å¤„ç†"""
        from .react_agent import ReActAgent, ReActPromptBuilder

        # åˆ›å»º ReAct Agent
        react_agent = ReActAgent(
            resume_data=self.resume_data,
            capability=self.capability,
            session_id=self.session_id,
            max_steps=self.config.react_max_steps,
        )
        react_agent.llm_call_fn = self._create_react_llm_wrapper()

        # è¿è¡Œ ReActï¼ˆåŒæ­¥æ–¹å¼ï¼Œæ”¶é›†æ‰€æœ‰è¾“å‡ºï¼‰
        import asyncio

        final_content = ""
        try:
            # åœ¨æ–°äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            async def collect():
                content = ""
                async for event in react_agent.run(user_message):
                    if event.get("type") in ["content", "final_answer"]:
                        content = event.get("content", content)
                return content

            final_content = loop.run_until_complete(collect())
            loop.close()

        except Exception as e:
            if self.config.debug:
                print(f"[HybridAgent] ReAct é”™è¯¯: {e}")
            final_content = f"å¤„ç†å‡ºé”™: {e}"

        # æ·»åŠ åˆ°å†å²
        self.chat_history.append({"role": "assistant", "content": final_content})

        return MessageBuilder.text(content=final_content, session_id=self.session_id)

    def _process_stream_with_react(
        self,
        user_message: str,
        classification: ClassificationResult
    ) -> Generator[Dict[str, Any], None, None]:
        """ä½¿ç”¨ ReAct æµå¼å¤„ç†"""
        from .react_agent import ReActAgent

        yield {
            "type": "thinking",
            "content": f"ğŸ“¥ æ¥æ”¶: {user_message[:30]}...\nğŸ§  ä½¿ç”¨ ReAct æ¨ç†æ¨¡å¼",
            "session_id": self.session_id,
        }

        # åˆ›å»º ReAct Agent
        react_agent = ReActAgent(
            resume_data=self.resume_data,
            capability=self.capability,
            session_id=self.session_id,
            max_steps=self.config.react_max_steps,
        )
        react_agent.llm_call_fn = self._create_react_llm_wrapper()

        # è¿è¡Œ ReAct å¹¶è½¬å‘äº‹ä»¶
        import asyncio

        try:
            # åœ¨æ–°äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            async def forward_events():
                async for event in react_agent.run(user_message):
                    # æ·»åŠ  session_id
                    event["session_id"] = self.session_id
                    # è½¬æ¢ä¸ºåŒæ­¥ yield
                    yield event

            # æ”¶é›†æ‰€æœ‰äº‹ä»¶
            events = []
            async def collect():
                async for event in react_agent.run(user_message):
                    events.append(event)

            loop.run_until_complete(collect())
            loop.close()

            # ç”Ÿæˆäº‹ä»¶
            for event in events:
                yield event

        except Exception as e:
            if self.config.debug:
                print(f"[HybridAgent] ReAct æµå¼é”™è¯¯: {e}")
            yield {
                "type": "error",
                "content": f"ReAct å¤„ç†å‡ºé”™: {e}",
                "session_id": self.session_id,
            }

    # ========== å·¥å…·æ–¹æ³• ==========

    def _build_messages_for_llm(self, user_message: str) -> List[Dict[str, str]]:
        """æ„å»º LLM æ¶ˆæ¯"""
        # System Prompt
        system_prompt = self._build_system_prompt()

        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ ä¸Šä¸‹æ–‡ï¼ˆå¯¹è¯å†å²ï¼‰
        context_messages = self.state.get_context_for_llm(
            current_message=user_message,
            resume_summary=self._get_resume_summary()
        )
        messages.extend(context_messages)

        return messages

    def _build_system_prompt(self) -> str:
        """æ„å»º System Prompt"""
        base_prompt = """ä½ æ˜¯ RA AIï¼Œä¸€ä¸ªä¸“ä¸šçš„ç®€å†åŠ©æ‰‹ã€‚

ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ç”¨ï¼š
- CVReader: è¯»å–ç®€å†æ•°æ®
- CVEditor: ç¼–è¾‘ç®€å†ï¼ˆupdate/add/deleteï¼‰
- CVBatchEditor: æ‰¹é‡ç¼–è¾‘

ç›´æ¥ä½¿ç”¨å·¥å…·å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼Œä¸éœ€è¦é¢å¤–çš„æ€è€ƒæ­¥éª¤ã€‚
"""

        # æ·»åŠ  Capability æŒ‡ä»¤
        if self.capability.system_prompt_addendum:
            base_prompt += f"\n\n{self.capability.system_prompt_addendum}"

        return base_prompt

    def _get_resume_summary(self) -> str:
        """è·å–ç®€å†æ‘˜è¦"""
        parts = []
        basic = self.resume_data.get("basic", {})
        if basic.get("name"):
            parts.append(f"å§“å:{basic['name']}")

        for key, label in [
            ("education", "æ•™è‚²"),
            ("workExperience", "å·¥ä½œç»å†"),
            ("projects", "é¡¹ç›®"),
        ]:
            items = self.resume_data.get(key, [])
            if items:
                parts.append(f"{label}:{len(items)}æ¡")

        return ", ".join(parts) if parts else "ç©ºç®€å†"

    def _get_function_calling_tools(self) -> List[Dict]:
        """è·å– Function Calling å·¥å…·å®šä¹‰"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "CVReader",
                    "description": "è¯»å–ç®€å†æ•°æ®",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "path": {"type": "string", "description": "å­—æ®µè·¯å¾„"}
                        }
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "CVEditor",
                    "description": "ç¼–è¾‘ç®€å†",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "path": {"type": "string"},
                            "action": {"type": "string", "enum": ["update", "add", "delete"]},
                            "value": {"description": "æ–°å€¼"}
                        },
                        "required": ["path", "action"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "CVBatchEditor",
                    "description": "æ‰¹é‡ç¼–è¾‘ç®€å†",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "operations": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "path": {"type": "string"},
                                        "action": {"type": "string", "enum": ["update", "add", "delete"]},
                                        "value": {}
                                    },
                                    "required": ["path", "action"]
                                }
                            }
                        },
                        "required": ["operations"]
                    }
                }
            }
        ]

    def _handle_tool_calls(self, response: Dict, messages: List[Dict]) -> AgentMessage:
        """å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆéæµå¼ï¼‰"""
        # è¿™é‡Œéœ€è¦å®ç°å·¥å…·æ‰§è¡Œé€»è¾‘
        # æš‚æ—¶è¿”å›æˆåŠŸæ¶ˆæ¯
        return MessageBuilder.text(
            content="å·¥å…·è°ƒç”¨å·²å¤„ç†ï¼ˆå¾…å®ç°ï¼‰",
            session_id=self.session_id
        )

    def _handle_tool_calls_stream(
        self,
        tool_calls: List[Dict],
        messages: List[Dict],
        user_message: str
    ) -> Generator[Dict[str, Any], None, None]:
        """æµå¼å¤„ç†å·¥å…·è°ƒç”¨"""
        # è¿™é‡Œéœ€è¦å®ç°å·¥å…·æ‰§è¡Œé€»è¾‘
        # æš‚æ—¶è¿”å›æˆåŠŸæ¶ˆæ¯
        yield {
            "type": "content",
            "content": "å·¥å…·è°ƒç”¨å·²å¤„ç†ï¼ˆå¾…å®ç°ï¼‰",
            "session_id": self.session_id,
        }

    def _create_react_llm_wrapper(self):
        """åˆ›å»º ReAct LLM åŒ…è£…å™¨"""
        # å°†åŒæ­¥çš„ llm_call_fn åŒ…è£…æˆ ReAct éœ€è¦çš„æ ¼å¼
        def wrapper(prompt: str) -> str:
            messages = [{"role": "user", "content": prompt}]
            response = self.llm_call_fn(
                messages=messages,
                temperature=self.config.react_temperature
            )
            return response.get("content", "")

        return wrapper

    # ========== ç»Ÿè®¡æ–¹æ³• ==========

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            "function_calling_ratio": (
                self.stats["function_calling_count"] / self.stats["total_requests"]
                if self.stats["total_requests"] > 0 else 0
            ),
            "react_ratio": (
                self.stats["react_count"] / self.stats["total_requests"]
                if self.stats["total_requests"] > 0 else 0
            ),
        }

    def reset_stats(self) -> None:
        """é‡ç½®ç»Ÿè®¡"""
        self.stats = {
            "total_requests": 0,
            "function_calling_count": 0,
            "react_count": 0,
            "mode_selections": [],
        }


# ä¾¿æ·å‡½æ•°
def create_hybrid_agent(
    resume_data: Optional[Dict[str, Any]] = None,
    session_id: str = "",
    capability: Optional[str] = None,
    mode: ExecutionMode = ExecutionMode.AUTO,
    llm_call_fn: Optional[Callable] = None,
) -> HybridAgent:
    """
    åˆ›å»ºæ··åˆ Agent

    Args:
        resume_data: ç®€å†æ•°æ®
        session_id: ä¼šè¯ ID
        capability: èƒ½åŠ›åŒ…åç§°
        mode: æ‰§è¡Œæ¨¡å¼
        llm_call_fn: LLM è°ƒç”¨å‡½æ•°

    Returns:
        HybridAgent å®ä¾‹
    """
    cap = CapabilityRegistry.get(capability) if capability else BASE_CAPABILITY
    config = HybridAgentConfig(mode=mode)

    return HybridAgent(
        resume_data=resume_data,
        session_id=session_id,
        capability=cap,
        config=config,
        llm_call_fn=llm_call_fn,
    )
