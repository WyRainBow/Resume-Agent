"""Agent stream output handler.

Handles streaming agent execution results to SSE clients.
ç°å·²é›†æˆ CLTP chunks çš„ç”Ÿæˆä¸å…¼å®¹è¾“å‡ºã€‚
ä½¿ç”¨ä¸åŸå§‹ server.py ç›¸åŒçš„æ‰‹åŠ¨æ­¥éª¤å¾ªç¯é€»è¾‘ã€‚
"""

import asyncio
import json
import logging
import re
from typing import Any, AsyncIterator, Callable, Optional, Tuple, List, Set
from datetime import datetime


def parse_thought_response(content: str) -> Tuple[Optional[str], Optional[str]]:
    """
    è§£æ LLM è¾“å‡ºä¸­çš„ Thought å’Œ Response éƒ¨åˆ†

    Deprecated: CLTP å·²æä¾›æ ‡å‡†çš„ think/plain content chunksï¼Œ
    åç»­åœ¨å®Œæˆå‰ç«¯è¿ç§»åç§»é™¤æ­¤å‡½æ•°ä¸ç›¸å…³è°ƒç”¨ã€‚
    TODO(cltp): å‰ç«¯å®Œå…¨è¿ç§»ååˆ é™¤ parse_thought_response

    Returns:
        (thought, response) - å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”éƒ¨åˆ†åˆ™ä¸º None
    """
    # #region debug log (å·²ç¦ç”¨ç¡¬ç¼–ç è·¯å¾„)
    import json
    # ä½¿ç”¨ logger ä»£æ›¿ç¡¬ç¼–ç è·¯å¾„ï¼Œé¿å…åœ¨ä¸åŒç³»ç»Ÿä¸Šå‡ºé”™
    try:
        logger.debug(f"[DEBUG] parse_thought_response called: content_length={len(content) if content else 0}")
    except Exception:
        pass
    # #endregion

    thought = None
    response = None

    if not content or not content.strip():
        """
        # debug log (å·²ç¦ç”¨)
        with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({
                "sessionId": "debug-session",
                "runId": "run1",
                "hypothesisId": "C",
                "location": "agent_stream.py:parse_thought_response:EMPTY",
                "message": "content is empty or whitespace",
                "data": {"content": content},
                "timestamp": int(__import__('time').time() * 1000)
            }) + '\n')
        """
        return None, None

    # ä½¿ç”¨æ›´ä¸¥è°¨çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… Thought: å’Œ Response:
    # è€ƒè™‘å¯èƒ½å­˜åœ¨çš„æ¢è¡Œå’Œç©ºæ ¼ï¼Œæ”¯æŒå¤šç§æ ¼å¼å˜ä½“
    # åŒ¹é…æ¨¡å¼ï¼š
    # 1. Thought: ... Response: ...
    # 2. **Thought:** ... **Response:** ...
    # 3. Thought: ... (æ²¡æœ‰ Response)
    # 4. æ€è€ƒï¼š... å›å¤ï¼š... (ä¸­æ–‡æ ¼å¼)

    # å°è¯•å¤šç§åŒ¹é…æ¨¡å¼
    patterns = [
        # æ ‡å‡†æ ¼å¼ï¼šThought: ... Response: ...
        (r'(?:^|\n)\s*(?:Thought|æ€è€ƒ)[:ï¼š]\s*(.*?)(?=\n\s*(?:Response|å›å¤)[:ï¼š]|$)',
         r'(?:^|\n)\s*(?:Response|å›å¤)[:ï¼š]\s*(.*)'),
        # åŠ ç²—æ ¼å¼ï¼š**Thought:** ... **Response:** ...
        (r'(?:^|\n)\s*\*\*Thought\*\*[:ï¼š]\s*(.*?)(?=\n\s*\*\*Response\*\*[:ï¼š]|$)',
         r'(?:^|\n)\s*\*\*Response\*\*[:ï¼š]\s*(.*)'),
        # 1. Thought: ... 2. Response: ... (å¸¦ç¼–å·)
        (r'(?:^|\n)\s*1\.\s*(?:Thought|æ€è€ƒ)[:ï¼š]\s*(.*?)(?=\n\s*2\.\s*(?:Response|å›å¤)[:ï¼š]|$)',
         r'(?:^|\n)\s*2\.\s*(?:Response|å›å¤)[:ï¼š]\s*(.*)'),
    ]

    for idx, (thought_pattern, response_pattern) in enumerate(patterns):
        thought_match = re.search(thought_pattern, content, re.DOTALL | re.IGNORECASE | re.MULTILINE)
        response_match = re.search(response_pattern, content, re.DOTALL | re.IGNORECASE | re.MULTILINE)

        if thought_match:
            thought = thought_match.group(1).strip()
        if response_match:
            response = response_match.group(1).strip()

        """
        # debug log (å·²ç¦ç”¨)
        if thought_match or response_match:
            with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
                f.write(json.dumps({
                    "sessionId": "debug-session",
                    "runId": "run1",
                    "hypothesisId": "B",
                    "location": f"agent_stream.py:parse_thought_response:PATTERN_{idx}",
                    "message": "pattern matched",
                    "data": {
                        "pattern_idx": idx,
                        "thought_matched": thought_match is not None,
                        "response_matched": response_match is not None,
                        "thought_preview": thought[:100] if thought else None,
                        "response_preview": response[:100] if response else None
                    },
                    "timestamp": int(__import__('time').time() * 1000)
                }) + '\n')
        """

        if thought or response:
            break

    # å¦‚æœæ‰¾åˆ°äº† Thought ä½†æ²¡æ‰¾åˆ° Responseï¼ˆè¿˜åœ¨ç”Ÿæˆä¸­ï¼‰ï¼Œæˆ–è€…æ‰¾åˆ°äº† Response
    if thought or response:
        """
        # debug log (å·²ç¦ç”¨)
        with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
            f.write(json.dumps({
                "sessionId": "debug-session",
                "runId": "run1",
                "hypothesisId": "B",
                "location": "agent_stream.py:parse_thought_response:SUCCESS",
                "message": "parse_thought_response success",
                "data": {
                    "thought_found": thought is not None,
                    "response_found": response is not None,
                    "thought_length": len(thought) if thought else 0,
                    "response_length": len(response) if response else 0
                },
                "timestamp": int(__import__('time').time() * 1000)
            }) + '\n')
        """
        return thought, response

    # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°æ ¼å¼åŒ–çš„è¾“å‡ºï¼Œè¿”å›åŸå§‹å†…å®¹ä½œä¸º response
    # #region debug log (å·²ç¦ç”¨ç¡¬ç¼–ç è·¯å¾„)
    # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
    #     f.write(json.dumps({
    #         "sessionId": "debug-session",
    #         "runId": "run1",
    #         "hypothesisId": "A",
    #         "location": "agent_stream.py:parse_thought_response:NO_MATCH",
    #         "message": "no pattern matched, returning original content as response",
    #         "data": {
    #             "content_preview": content[:200],
    #             "content_contains_thought": "Thought:" in content or "æ€è€ƒ:" in content or "**Thought**" in content,
    #             "content_contains_response": "Response:" in content or "å›å¤:" in content or "**Response**" in content
    #         },
    #         "timestamp": int(__import__('time').time() * 1000)
    #     }) + '\n')
    # #endregion
    return None, content

from backend.agent.agent.manus import Manus
from backend.agent.schema import AgentState as SchemaAgentState, Message, Role
from backend.agent.web.streaming.events import (
    EventType,
    StreamEvent,
    ThoughtEvent,
    ToolCallEvent,
    ToolResultEvent,
    AnswerEvent,
    AgentStartEvent,
    AgentEndEvent,
    AgentErrorEvent,
    SystemEvent,
)
from backend.agent.web.streaming.agent_state import AgentState, StateInfo
from backend.agent.web.streaming.state_machine import AgentStateMachine
from backend.agent.cltp.chunk_generator import CLTPChunkGenerator
from backend.agent.cltp.chunk_to_sse import chunk_to_sse

logger = logging.getLogger(__name__)


EventSender = Callable[[dict[str, Any]], asyncio.Task]

# åˆ†æç»“æœæ ‡è®°
ANALYSIS_RESULT_MARKERS = [
    "ğŸ“Š åˆ†æç»“æœæ‘˜è¦",
    "ğŸ’¡ ä¼˜åŒ–å»ºè®®",
    "ğŸ¯ æˆ‘æœ€æ¨èçš„ä¼˜åŒ–",
    "æ˜¯å¦è¦åº”ç”¨è¿™ä¸ªä¼˜åŒ–",
    "æ˜¯å¦è¦ä¼˜åŒ–",
    "æ˜¯å¦è¦ä¼˜åŒ–è¿™æ®µæ•™è‚²ç»å†",
    "ç»¼åˆè¯„åˆ†"
]


class AgentStream:
    """Handles streaming agent execution to WebSocket.

    ä½¿ç”¨ä¸åŸå§‹ server.py ç›¸åŒçš„æ‰§è¡Œé€»è¾‘ï¼š
    - æ‰‹åŠ¨æ­¥éª¤å¾ªç¯
    - è°ƒç”¨ agent.step()
    - å‘é€ step, thought, tool_call, tool_result, answer äº‹ä»¶
    - å»é‡ï¼šé˜²æ­¢å‘é€é‡å¤å†…å®¹
    """

    def __init__(
        self,
        agent: Manus,
        session_id: str,
        state_machine: AgentStateMachine,
        event_sender: EventSender,
        chat_history_manager: Optional[Any] = None,
    ) -> None:
        """Initialize the agent stream.

        Args:
            agent: The Manus agent instance
            session_id: Unique session identifier
            state_machine: The state machine for tracking execution
            event_sender: Async function to send events
            chat_history_manager: Optional chat history manager
        """
        self.agent = agent
        self._session_id = session_id
        self._state_machine = state_machine
        self._send_event = event_sender
        self._chat_history_manager = chat_history_manager

        # ğŸš¨ å»é‡ï¼šè·Ÿè¸ªå·²å‘é€çš„å†…å®¹
        self._sent_thoughts: set[str] = set()
        self._sent_tools: set[str] = set()
        self._last_answer_content: str = ""
        self._answer_sent_in_loop: bool = False  # ğŸš¨ è·Ÿè¸ªå¾ªç¯ä¸­æ˜¯å¦å·²å‘é€è¿‡ answer

        # CLTP chunk generator
        self._cltp_generator = CLTPChunkGenerator(session_id)

    def _ensure_assistant_message(self, content: Optional[str]) -> None:
        """Ensure the assistant message is present in memory for persistence."""
        if not content or not content.strip():
            return
        
        content_clean = content.strip()
        
        # æå– Response éƒ¨åˆ†ï¼ˆå¦‚æœå­˜åœ¨ Thought: ... Response: æ ¼å¼ï¼‰
        content_response_part = content_clean
        if "Response:" in content_clean:
            # å¦‚æœ content åŒ…å« Response:ï¼Œæå– Response: ä¹‹åçš„éƒ¨åˆ†
            content_response_part = content_clean.split("Response:")[-1].strip()
        
        for msg in reversed(self.agent.memory.messages):
            if msg.role == Role.ASSISTANT:
                msg_content = (msg.content or "").strip()
                
                # å®Œå…¨åŒ¹é…
                if msg_content == content_clean:
                    return
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ Thought + Response æ ¼å¼ï¼Œä¸” Response éƒ¨åˆ†åŒ¹é…
                if "Response:" in msg_content:
                    msg_response_part = msg_content.split("Response:")[-1].strip()
                    # å¦‚æœ content çš„ Response éƒ¨åˆ†ä¸å·²å­˜åœ¨çš„ Response éƒ¨åˆ†ç›¸åŒ
                    if msg_response_part == content_response_part:
                        return
                    # å¦‚æœ content å®Œå…¨ç­‰äºå·²å­˜åœ¨çš„ Response éƒ¨åˆ†
                    if msg_response_part == content_clean:
                        return
                
                # æ£€æŸ¥åå‘ï¼šcontent_clean æ˜¯å¦åŒ…å«åœ¨ msg_content ä¸­ï¼ˆä½œä¸ºå­ä¸²ï¼‰
                if content_clean in msg_content:
                    return
                
                # æ£€æŸ¥åå‘ï¼šmsg_content çš„ Response éƒ¨åˆ†æ˜¯å¦åŒ…å« content_clean
                if "Response:" in msg_content:
                    msg_response_part = msg_content.split("Response:")[-1].strip()
                    if content_clean in msg_response_part:
                        return
                
                break
        
        self.agent.memory.add_message(Message.assistant_message(content))

    def _serialize_tool_calls(self, tool_calls: Any) -> str:
        """Serialize tool calls for deduplication."""
        if not tool_calls:
            return ""
        normalized: List[Any] = []
        for call in tool_calls:
            if hasattr(call, "model_dump"):
                normalized.append(call.model_dump())
            elif hasattr(call, "dict"):
                normalized.append(call.dict())
            elif isinstance(call, dict):
                normalized.append(call)
            else:
                normalized.append(str(call))
        return json.dumps(normalized, ensure_ascii=False, sort_keys=True, default=str)

    def _dedupe_messages(self, messages: List[Message]) -> List[Message]:
        """å»é‡æ¶ˆæ¯åˆ—è¡¨ï¼Œé˜²æ­¢é‡å¤ä¿å­˜åˆ°å†å²è®°å½•ã€‚"""
        if not messages:
            return messages

        deduped: List[Message] = []
        seen_keys: Set[str] = set()

        for msg in messages:
            if msg.role == Role.USER:
                # ç”¨æˆ·æ¶ˆæ¯å·²åœ¨ stream.py ä¸­å†™å…¥ history
                continue

            content = (msg.content or "").strip()
            if msg.role == Role.ASSISTANT:
                response_part = content
                if "Response:" in content:
                    response_part = content.split("Response:")[-1].strip()

                tool_calls_str = self._serialize_tool_calls(msg.tool_calls)
                key = f"assistant|||{content}|||{tool_calls_str}"
                response_key = None
                if response_part and response_part != content:
                    response_key = f"assistant|||{response_part}|||{tool_calls_str}"

                if key in seen_keys or (response_key and response_key in seen_keys):
                    logger.debug(
                        f"[AgentStream] Skip duplicate assistant message: {content[:50]}..."
                    )
                    continue

                seen_keys.add(key)
                if response_key:
                    seen_keys.add(response_key)

            elif msg.role == Role.TOOL:
                key = f"tool|||{msg.name}|||{msg.tool_call_id}|||{content}"
                if key in seen_keys:
                    logger.debug(
                        f"[AgentStream] Skip duplicate tool message: {msg.name}"
                    )
                    continue
                seen_keys.add(key)
            else:
                key = f"{msg.role}|||{content}"
                if key in seen_keys:
                    continue
                seen_keys.add(key)

            deduped.append(msg)

        return deduped

    async def execute(self, user_message: str) -> AsyncIterator[StreamEvent]:
        """Execute agent with streaming events.

        ä½¿ç”¨æ‰‹åŠ¨æ­¥éª¤å¾ªç¯ï¼Œä¸åŸå§‹ server.py é€»è¾‘ç›¸åŒã€‚

        Args:
            user_message: The user's input message

        Yields:
            StreamEvent instances during execution
        """
        start_memory_len = len(self.agent.memory.messages)
        try:
            # Start state
            await self._state_machine.transition_to(
                AgentState.STARTING,
                message="Starting agent execution",
                data={"user_message": user_message},
            )

            # ç”Ÿæˆ CLTP span:start(name='run') chunk
            run_start_chunk = self._cltp_generator.emit_span_start('run')
            # è½¬æ¢ä¸º SSE æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            yield AgentStartEvent(
                agent_name="Manus",
                task=user_message,
                session_id=self._session_id,
            )

            # Running state
            await self._state_machine.transition_to(AgentState.RUNNING)

            # ç¡®ä¿æ™ºèƒ½ä½“å¤„äº IDLE çŠ¶æ€
            if self.agent.state != SchemaAgentState.IDLE:
                self.agent.state = SchemaAgentState.IDLE
                self.agent.current_step = 0

            # æ¸…ç†ä¸å®Œæ•´çš„æ¶ˆæ¯åºåˆ—
            self.agent.memory.cleanup_incomplete_sequences()

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ° memory
            self.agent.memory.add_message(Message.user_message(user_message))

            # åŒæ­¥åˆ° LangChain Memory
            if hasattr(self.agent, '_langchain_memory') and self.agent._langchain_memory:
                self.agent._langchain_memory.add_user_message(user_message)

            # é‡ç½® answer å‘é€æ ‡å¿—
            self._answer_sent_in_loop = False

            # æ ¹æ®ä»»åŠ¡ç±»å‹åŠ¨æ€è°ƒæ•´æœ€å¤§æ­¥æ•°
            if any(keyword in user_message.lower() for keyword in ["åˆ†æ", "analyze", "æ·±å…¥", "è¯¦ç»†"]):
                max_steps = 10
            else:
                max_steps = 5

            # è®°å½•æœ€åå‘é€çš„æ€è€ƒå†…å®¹
            last_sent_thought = None

            # æ‰‹åŠ¨æ‰§è¡Œæ­¥éª¤å¾ªç¯
            async with self.agent.state_context(SchemaAgentState.RUNNING):
                while self.agent.current_step < max_steps and self.agent.state != SchemaAgentState.FINISHED:
                    if self._state_machine.stop_requested:
                        await self._state_machine.transition_to(AgentState.STOPPED)
                        yield SystemEvent(
                            message="Execution stopped by user",
                            level="info",
                            session_id=self._session_id,
                        )
                        return

                    self.agent.current_step += 1

                    # å‘é€æ­¥éª¤äº‹ä»¶
                    yield SystemEvent(
                        message=f"æ‰§è¡Œæ­¥éª¤ {self.agent.current_step}/{max_steps}",
                        level="info",
                        session_id=self._session_id,
                    )

                    # è®°å½•æ‰§è¡Œå‰çš„æ¶ˆæ¯æ•°é‡
                    msg_count_before = len(self.agent.memory.messages)

                    # æ‰§è¡Œä¸€æ­¥
                    step_result = await self.agent.step()
                    logger.info(f"ğŸ” [DEBUG] step() è¿”å›: {step_result}, agent.state: {self.agent.state}, _answer_sent_in_loop: {self._answer_sent_in_loop}")

                    # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥çŠ¶æ€å˜åŒ–
                    if self.agent.state == SchemaAgentState.FINISHED:
                        logger.info(f"âœ… Agent çŠ¶æ€å·²è®¾ç½®ä¸º FINISHEDï¼Œå‡†å¤‡é€€å‡ºå¾ªç¯")
                        # ğŸ”‘ å…³é”®ä¿®å¤ï¼šå¦‚æœçŠ¶æ€æ˜¯ FINISHEDï¼Œç«‹å³é€€å‡ºå¾ªç¯
                        # å…ˆå‘é€æœ€ç»ˆç­”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
                        final_answer = None
                        # æŸ¥æ‰¾ assistant æ¶ˆæ¯çš„ content
                        for msg in reversed(self.agent.memory.messages):
                            if msg.role == "assistant" and msg.content:
                                final_answer = msg.content
                                break
                        
                        # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼ŒæŸ¥æ‰¾ä»»ä½•æœ‰å†…å®¹çš„ assistant æ¶ˆæ¯ï¼ˆå³ä½¿åªæœ‰ tool_callsï¼‰
                        # æ³¨æ„ï¼šæ’é™¤ terminate å·¥å…·çš„ç»“æœï¼Œå› ä¸ºå®ƒæ˜¯æŠ€æœ¯æ€§æ¶ˆæ¯
                        if not final_answer:
                            for msg in reversed(self.agent.memory.messages):
                                if msg.role == "assistant":
                                    # å¦‚æœæœ‰ contentï¼Œä½¿ç”¨å®ƒ
                                    if msg.content:
                                        final_answer = msg.content
                                        break
                                    # å¦‚æœåªæœ‰ tool_callsï¼Œå°è¯•ä» tool ç»“æœä¸­è·å–ï¼ˆæ’é™¤ terminateï¼‰
                                    elif msg.tool_calls:
                                        # æŸ¥æ‰¾å¯¹åº”çš„ tool æ¶ˆæ¯
                                        for tool_msg in reversed(self.agent.memory.messages):
                                            # æ’é™¤ terminate å·¥å…·çš„ç»“æœ
                                            if tool_msg.role == "tool" and tool_msg.name != "terminate" and tool_msg.tool_call_id in [tc.id for tc in msg.tool_calls]:
                                                if tool_msg.content:
                                                    final_answer = tool_msg.content
                                                    logger.info(f"ğŸ” [DEBUG] ä» tool æ¶ˆæ¯ä¸­è·å– final_answer: {final_answer[:100]}...")
                                                    break
                                        if final_answer:
                                            break
                        
                        # ğŸ”‘ Fallbackï¼šå¦‚æœæ²¡æœ‰æ‰¾åˆ° final_answer ä¸” Agent å·²å®Œæˆï¼Œæä¾›ä¸€ä¸ªå‹å¥½çš„é»˜è®¤å›å¤
                        if not final_answer and not self._answer_sent_in_loop:
                            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº† terminate å·¥å…·
                            has_terminate = any(
                                msg.role == "tool" and msg.name == "terminate" 
                                for msg in self.agent.memory.messages
                            )
                            if has_terminate:
                                final_answer = "å¥½çš„ï¼Œè¿˜æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
                                logger.info("ğŸ” [DEBUG] ä½¿ç”¨é»˜è®¤å‹å¥½å›å¤ä½œä¸º final_answer")

                        logger.info(f"ğŸ” [DEBUG] FINISHED çŠ¶æ€æ£€æŸ¥: final_answer={final_answer[:100] if final_answer else None}..., _answer_sent_in_loop={self._answer_sent_in_loop}")

                        if final_answer and not self._answer_sent_in_loop:
                            # #region debug log
                            import json
                            # ä½¿ç”¨ logger ä»£æ›¿ç¡¬ç¼–ç è·¯å¾„
                            try:
                                debug_data = {
                                    "sessionId": "debug-session",
                                    "runId": "run1",
                                    "hypothesisId": "D",
                                    "location": "agent_stream.py:execute:FINISHED_BEFORE_PARSE",
                                    "message": "before parse_thought_response in FINISHED state",
                                    "data": {
                                        "final_answer_length": len(final_answer) if final_answer else 0,
                                        "final_answer_preview": final_answer[:300] if final_answer else None
                                    },
                                    "timestamp": int(__import__('time').time() * 1000)
                                }
                                logger.debug(f"[DEBUG] FINISHED_BEFORE_PARSE: {json.dumps(debug_data, ensure_ascii=False)}")
                            except Exception:
                                pass
                            # æ³¨é‡Šæ‰ç¡¬ç¼–ç è·¯å¾„çš„è°ƒè¯•æ—¥å¿—
            # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
            #     f.write(json.dumps({
            #         "sessionId": "debug-session",
            #         "runId": "run1",
            #         "hypothesisId": "D",
            #         "location": "agent_stream.py:execute:FINISHED_BEFORE_PARSE",
            #         "message": "before parse_thought_response in FINISHED state",
            #         "data": {
            #             "final_answer_length": len(final_answer) if final_answer else 0,
            #             "final_answer_preview": final_answer[:300] if final_answer else None
            #         },
            #         "timestamp": int(__import__('time').time() * 1000)
            #     }) + '\n')
                            # #endregion

                            # ğŸ¯ è§£æ Thought å’Œ Response
                            thought_part, response_part = parse_thought_response(final_answer)
                            logger.info(f"[FINISHED è§£æ] thought={thought_part[:50] if thought_part else None}... response={response_part[:50] if response_part else None}...")

                            # #region debug log (å·²ç¦ç”¨ç¡¬ç¼–ç è·¯å¾„)
            # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
            #     f.write(json.dumps({
            #         "sessionId": "debug-session",
            #         "runId": "run1",
            #         "hypothesisId": "D",
            #         "location": "agent_stream.py:execute:FINISHED_AFTER_PARSE",
            #         "message": "after parse_thought_response in FINISHED state",
            #         "data": {
            #             "thought_part_found": thought_part is not None,
            #             "response_part_found": response_part is not None,
            #             "thought_part_length": len(thought_part) if thought_part else 0,
            #             "response_part_length": len(response_part) if response_part else 0
            #         },
            #         "timestamp": int(__import__('time').time() * 1000)
            #     }) + '\n')
                            # #endregion

                            # å…ˆå‘é€ Thoughtï¼ˆå¦‚æœæœ‰ï¼‰
                            if thought_part:
                                logger.info(f"[Thought Process] {thought_part[:100]}...")
                                # #region debug log
            # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
            #     f.write(json.dumps({
            #         "sessionId": "debug-session",
            #         "runId": "run1",
            #         "hypothesisId": "D",
            #         "location": "agent_stream.py:execute:YIELD_THOUGHT",
            #         "message": "yielding ThoughtEvent",
            #         "data": {
            #             "thought_length": len(thought_part),
            #             "thought_preview": thought_part[:100]
            #         },
            #         "timestamp": int(__import__('time').time() * 1000)
            #     }) + '\n')
                                # #endregion

                                # ç”Ÿæˆ CLTP content(channel='think') chunk
                                # å…³é”®ï¼šä¿æŒæ–‡æœ¬å†…å®¹åŸæ ·ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                                think_chunk = self._cltp_generator.emit_content(
                                    channel='think',
                                    payload={'text': thought_part},  # ä¿æŒåŸæ ·
                                    done=False,
                                )

                                yield ThoughtEvent(
                                    thought=thought_part,
                                    session_id=self._session_id,
                                )
                            else:
                                # #region debug log (å·²ç¦ç”¨ç¡¬ç¼–ç è·¯å¾„)
                                # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
                                #     f.write(json.dumps({
                                #         "sessionId": "debug-session",
                                #         "runId": "run1",
                                #         "hypothesisId": "D",
                                #         "location": "agent_stream.py:execute:NO_THOUGHT",
                                #         "message": "thought_part is None, not yielding ThoughtEvent",
                                #         "data": {},
                                #         "timestamp": int(__import__('time').time() * 1000)
                                #     }) + '\n')
                                # #endregion
                                pass

                            # å†å‘é€ Response
                            final_content = response_part if response_part else final_answer

                            # ç”Ÿæˆ CLTP content(channel='plain', done=true) chunk
                            # å…³é”®ï¼šä¿æŒæ–‡æœ¬å†…å®¹åŸæ ·ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                            answer_chunk = self._cltp_generator.emit_content(
                                channel='plain',
                                payload={'text': final_content},  # ä¿æŒåŸæ ·
                                done=True,
                            )

                            # Ensure final response is stored for history persistence
                            self._ensure_assistant_message(final_content)

                            yield AnswerEvent(
                                content=final_content,
                                is_complete=True,
                                session_id=self._session_id,
                            )
                            self._answer_sent_in_loop = True

                        # é€€å‡ºå¾ªç¯
                        break

                    # å®æ—¶å‘é€æ–°å¢çš„æ¶ˆæ¯
                    new_messages = self.agent.memory.messages[msg_count_before:]

                    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æå·¥å…·ç»“æœ
                    has_recent_analysis_result = False
                    for msg in reversed(self.agent.memory.messages[-10:]):
                        if msg.role == "tool" and msg.name in ['education_analyzer', 'cv_analyzer_agent']:
                            has_recent_analysis_result = True
                            break

                    # å¤„ç†æ–°æ¶ˆæ¯
                    for msg in new_messages:
                        if msg.role == "assistant":
                            # å…ˆå¤„ç† tool_callsï¼ˆassistant æ¶ˆæ¯å¯ä»¥åŒæ—¶æœ‰ content å’Œ tool_callsï¼‰
                            if msg.tool_calls:
                                await self._state_machine.transition_to(AgentState.TOOL_EXECUTING)
                                for tool_call in msg.tool_calls:
                                    tool_name = tool_call.function.name
                                    tool_call_id = tool_call.id  # âœ… è·å– tool_call_id

                                    # ğŸš¨ å»é‡ï¼šä½¿ç”¨ tool_call_id è€Œä¸æ˜¯ step ä½œä¸ºé”®
                                    if tool_call_id in self._sent_tools:
                                        logger.info(f"[è·³è¿‡é‡å¤å·¥å…·] {tool_name} (ID: {tool_call_id[:8]}...)")
                                        continue
                                    self._sent_tools.add(tool_call_id)

                                    tool_args = tool_call.function.arguments
                                    safe_args = str(tool_args).replace("<", r"\<").replace(">", r"\>")
                                    logger.info(f"[å·¥å…·è°ƒç”¨] {tool_name} | ID: {tool_call_id} | å‚æ•°: {safe_args[:100]}...")
                                    yield ToolCallEvent(
                                        tool_name=tool_name,
                                        tool_args=tool_args if isinstance(tool_args, (dict, str)) else {},
                                        session_id=self._session_id,
                                        tool_call_id=tool_call_id,  # âœ… ä¼ é€’ tool_call_id
                                    )

                            # å†å¤„ç† contentï¼ˆå¦‚æœæœ‰ï¼‰
                            if msg.content:
                                # ğŸš¨ å»é‡ï¼šè·³è¿‡å·²å‘é€è¿‡çš„ç›¸åŒå†…å®¹
                                content_hash = hash(msg.content)  # ä½¿ç”¨å®Œæ•´å†…å®¹ï¼Œé¿å…æˆªæ–­æ›´æ–°è¢«è¯¯åˆ¤
                                if content_hash in self._sent_thoughts:
                                    logger.debug(f"[è·³è¿‡é‡å¤å†…å®¹] {msg.content[:50]}...")
                                    continue
                                self._sent_thoughts.add(content_hash)

                                # ğŸ¯ è§£æ Thought å’Œ Response æ ¼å¼
                                logger.info(f"[è§£æå‰] åŸå§‹å†…å®¹: {msg.content[:150]}...")

                                # #region debug log
                                import json
            # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
            #     f.write(json.dumps({
            #         "sessionId": "debug-session",
            #         "runId": "run1",
            #         "hypothesisId": "D",
            #         "location": "agent_stream.py:execute:LOOP_BEFORE_PARSE",
            #         "message": "before parse_thought_response in message loop",
            #         "data": {
            #             "msg_content_length": len(msg.content) if msg.content else 0,
            #             "msg_content_preview": msg.content[:300] if msg.content else None
            #         },
            #         "timestamp": int(__import__('time').time() * 1000)
            #     }) + '\n')
                                # #endregion

                                thought_part, response_part = parse_thought_response(msg.content)
                                logger.info(f"[è§£æå] thought={thought_part[:50] if thought_part else None}... response={response_part[:50] if response_part else None}...")

                                # #region debug log
            # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
            #     f.write(json.dumps({
            #         "sessionId": "debug-session",
            #         "runId": "run1",
            #         "hypothesisId": "D",
            #         "location": "agent_stream.py:execute:LOOP_AFTER_PARSE",
            #         "message": "after parse_thought_response in message loop",
            #         "data": {
            #             "thought_part_found": thought_part is not None,
            #             "response_part_found": response_part is not None,
            #             "thought_part_length": len(thought_part) if thought_part else 0,
            #             "response_part_length": len(response_part) if response_part else 0
            #         },
            #         "timestamp": int(__import__('time').time() * 1000)
            #     }) + '\n')
                                # #endregion

                                # åˆ¤æ–­æ˜¯å¦æ˜¯åˆ†æç»“æœå›å¤
                                check_content = response_part or msg.content
                                contains_analysis_result = any(
                                    marker in check_content for marker in ANALYSIS_RESULT_MARKERS
                                )
                                is_final_answer = has_recent_analysis_result and contains_analysis_result

                                # å…ˆå‘é€ Thoughtï¼ˆå¦‚æœæœ‰ï¼‰
                                if thought_part:
                                    logger.info(f"[Thought Process] {thought_part[:100]}...")
                                    # #region debug log
            # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
            #     f.write(json.dumps({
            #         "sessionId": "debug-session",
            #         "runId": "run1",
            #         "hypothesisId": "D",
            #         "location": "agent_stream.py:execute:LOOP_YIELD_THOUGHT",
            #         "message": "yielding ThoughtEvent in message loop",
            #         "data": {
            #             "thought_length": len(thought_part),
            #             "thought_preview": thought_part[:100]
            #         },
            #         "timestamp": int(__import__('time').time() * 1000)
            #     }) + '\n')
                                    # #endregion

                                    # ç”Ÿæˆ CLTP content(channel='think') chunk
                                    # å…³é”®ï¼šä¿æŒæ–‡æœ¬å†…å®¹åŸæ ·ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                                    think_chunk = self._cltp_generator.emit_content(
                                        channel='think',
                                        payload={'text': thought_part},  # ä¿æŒåŸæ ·
                                        done=False,
                                    )

                                    # è½¬æ¢ä¸º SSE æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                                    yield ThoughtEvent(
                                        thought=thought_part,
                                        session_id=self._session_id,
                                    )
                                else:
                                    # #region debug log (å·²ç¦ç”¨ç¡¬ç¼–ç è·¯å¾„)
                                    # with open('/Users/wy770/AI/.cursor/debug.log', 'a') as f:
                                    #     f.write(json.dumps({
                                    #         "sessionId": "debug-session",
                                    #         "runId": "run1",
                                    #         "hypothesisId": "D",
                                    #         "location": "agent_stream.py:execute:LOOP_NO_THOUGHT",
                                    #         "message": "thought_part is None in message loop, not yielding ThoughtEvent",
                                    #         "data": {},
                                    #         "timestamp": int(__import__('time').time() * 1000)
                                    #     }) + '\n')
                                    # #endregion
                                    pass

                                # å†å‘é€ Response/Answer
                                if response_part:
                                    if is_final_answer:
                                        logger.info(f"[åˆ†æç»“æœå›å¤] {response_part[:200]}...")
                                        self._answer_sent_in_loop = True

                                        # ç”Ÿæˆ CLTP content(channel='plain', done=true) chunk
                                        # å…³é”®ï¼šä¿æŒæ–‡æœ¬å†…å®¹åŸæ ·ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                                        answer_chunk = self._cltp_generator.emit_content(
                                            channel='plain',
                                            payload={'text': response_part},  # ä¿æŒåŸæ ·
                                            done=True,
                                        )

                                        yield AnswerEvent(
                                            content=response_part,
                                            is_complete=True,
                                            session_id=self._session_id,
                                        )
                                    else:
                                        logger.info(f"[Response] {response_part[:100]}...")

                                        # ç”Ÿæˆ CLTP content(channel='plain', done=false) chunk
                                        # å…³é”®ï¼šä¿æŒæ–‡æœ¬å†…å®¹åŸæ ·ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                                        answer_chunk = self._cltp_generator.emit_content(
                                            channel='plain',
                                            payload={'text': response_part},  # ä¿æŒåŸæ ·
                                            done=False,
                                        )

                                        yield AnswerEvent(
                                            content=response_part,
                                            is_complete=False,
                                            session_id=self._session_id,
                                        )
                                elif not thought_part:
                                    # æ²¡æœ‰æ ¼å¼åŒ–è¾“å‡ºï¼Œä½¿ç”¨åŸå§‹é€»è¾‘
                                    if is_final_answer:
                                        logger.info(f"[åˆ†æç»“æœå›å¤] {msg.content[:200]}...")
                                        self._answer_sent_in_loop = True

                                        # ç”Ÿæˆ CLTP content(channel='plain', done=true) chunk
                                        # å…³é”®ï¼šä¿æŒæ–‡æœ¬å†…å®¹åŸæ ·ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                                        answer_chunk = self._cltp_generator.emit_content(
                                            channel='plain',
                                            payload={'text': msg.content},  # ä¿æŒåŸæ ·
                                            done=True,
                                        )

                                        yield AnswerEvent(
                                            content=msg.content,
                                            is_complete=True,
                                            session_id=self._session_id,
                                        )
                                    else:
                                        # æ€è€ƒè¿‡ç¨‹ - æ ‡è®°ä¸º thought
                                        logger.debug(f"[æ€è€ƒè¿‡ç¨‹] {msg.content[:100]}...")

                                        # ç”Ÿæˆ CLTP content(channel='think') chunk
                                        # å…³é”®ï¼šä¿æŒæ–‡æœ¬å†…å®¹åŸæ ·ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                                        think_chunk = self._cltp_generator.emit_content(
                                            channel='think',
                                            payload={'text': msg.content},  # ä¿æŒåŸæ ·
                                            done=False,
                                        )

                                        yield ThoughtEvent(
                                            thought=msg.content,
                                            session_id=self._session_id,
                                        )

                        elif msg.tool_calls:
                            # é assistant æ¶ˆæ¯çš„ tool_callsï¼ˆfallbackï¼‰
                            await self._state_machine.transition_to(AgentState.TOOL_EXECUTING)
                            for tool_call in msg.tool_calls:
                                tool_name = tool_call.function.name
                                tool_call_id = tool_call.id  # âœ… è·å– tool_call_id
                                # ğŸš¨ å»é‡ï¼šä½¿ç”¨ tool_call_id è€Œä¸æ˜¯ step ä½œä¸ºé”®
                                if tool_call_id in self._sent_tools:
                                    logger.info(f"[è·³è¿‡é‡å¤å·¥å…·] {tool_name} (ID: {tool_call_id[:8]}...)")
                                    continue
                                self._sent_tools.add(tool_call_id)

                                tool_args = tool_call.function.arguments
                                safe_args = str(tool_args).replace("<", r"\<").replace(">", r"\>")
                                logger.info(f"[å·¥å…·è°ƒç”¨] {tool_name} | ID: {tool_call_id} | å‚æ•°: {safe_args[:100]}...")
                                yield ToolCallEvent(
                                    tool_name=tool_name,
                                    tool_args=tool_args if isinstance(tool_args, (dict, str)) else {},
                                    session_id=self._session_id,
                                    tool_call_id=tool_call_id,  # âœ… ä¼ é€’ tool_call_id
                                )

                        elif msg.role == "tool":
                            # Only transition if not already in THINKING state
                            if self._state_machine.current_state != AgentState.THINKING:
                                await self._state_machine.transition_to(AgentState.THINKING)
                            content = msg.content
                            tool_call_id = msg.tool_call_id  # âœ… è·å– tool_call_id
                            tool_name = msg.name or "unknown"

                            # æ¸…ç†å‰ç¼€
                            if content and content.startswith("Observed output of cmd `"):
                                prefix_pattern = r"Observed output of cmd `[^`]+` executed:\n"
                                content = re.sub(prefix_pattern, "", content, count=1)
                            elif content and content.startswith("Cmd `"):
                                content = "å·¥å…·æ‰§è¡Œå®Œæˆï¼Œæ— è¾“å‡ºå†…å®¹"

                            # é™åˆ¶æ˜¾ç¤ºé•¿åº¦
                            if content and len(content) > 5000:
                                content = content[:5000] + f"\n...(å†…å®¹å·²æˆªæ–­ï¼Œå…±{len(msg.content)}å­—ç¬¦)"

                            logger.info(f"[å·¥å…·ç»“æœ] {tool_name} | ID: {tool_call_id} | é•¿åº¦: {len(msg.content) if msg.content else 0} å­—ç¬¦")
                            structured_data = None
                            if tool_name == "web_search" and hasattr(
                                self.agent, "get_structured_tool_result"
                            ):
                                structured_data = self.agent.get_structured_tool_result(
                                    tool_call_id
                                )
                            yield ToolResultEvent(
                                tool_name=tool_name,
                                result=content or "",
                                is_error=False,
                                session_id=self._session_id,
                                tool_call_id=tool_call_id,  # âœ… ä¼ é€’ tool_call_id
                                structured_data=structured_data,
                            )
                            
                            # ğŸ”‘ å…³é”®ä¿®å¤ï¼šå¦‚æœæ‰§è¡Œäº† terminate å·¥å…·ï¼Œä¸”è¿˜æ²¡æœ‰å‘é€è¿‡ answer
                            # ä¸è¦å°†æŠ€æœ¯æ€§çš„ terminate æ¶ˆæ¯ä½œä¸ºæœ€ç»ˆç­”æ¡ˆï¼Œè€Œæ˜¯è·³è¿‡æˆ–ä½¿ç”¨å‹å¥½æ¶ˆæ¯
                            if tool_name == "terminate" and not self._answer_sent_in_loop:
                                logger.info(f"ğŸ” [DEBUG] terminate å·¥å…·æ‰§è¡Œå®Œæˆï¼Œä½†æ²¡æœ‰ answerï¼Œè·³è¿‡æŠ€æœ¯æ€§æ¶ˆæ¯")
                                # æ ‡è®°å·²å‘é€ï¼Œé˜²æ­¢åç»­å†æ¬¡å¤„ç†ï¼Œä½†ä¸å®é™…å‘é€æŠ€æœ¯æ€§æ¶ˆæ¯ç»™ç”¨æˆ·
                                self._answer_sent_in_loop = True

                    # æ£€æŸ¥æ˜¯å¦é™·å…¥å¾ªç¯
                    if self.agent.is_stuck():
                        logger.info("âš ï¸ Agent æ£€æµ‹åˆ°å¾ªç¯ï¼Œç»ˆæ­¢æ‰§è¡Œ")
                        break

                    # æ£€æŸ¥åˆ†æä»»åŠ¡æ˜¯å¦å®Œæˆ
                    if has_recent_analysis_result:
                        has_analysis_output = False
                        for msg in reversed(self.agent.memory.messages[-10:]):
                            if msg.role == "assistant" and msg.content:
                                contains_result = any(
                                    marker in msg.content for marker in ANALYSIS_RESULT_MARKERS
                                )
                                has_content = len(msg.content) > 100
                                no_more_tools = not msg.tool_calls or len(msg.tool_calls) == 0
                                if contains_result and has_content and no_more_tools:
                                    has_analysis_output = True
                                    logger.info(f"âœ… åˆ†æç»“æœå·²è¾“å‡º: {msg.content[:100]}...")
                                    break

                        if has_analysis_output:
                            logger.info("âœ… åˆ†æä»»åŠ¡å®Œæˆï¼Œç»ˆæ­¢å¾ªç¯")
                            self.agent.state = SchemaAgentState.FINISHED
                            break

            # é‡ç½®æ­¥éª¤è®¡æ•°
            self.agent.current_step = 0
            self.agent.state = SchemaAgentState.IDLE

            # åªæœ‰åœ¨å¾ªç¯ä¸­æ²¡æœ‰å‘é€è¿‡ answer çš„æƒ…å†µä¸‹ï¼Œæ‰å‘é€æœ€ç»ˆç­”æ¡ˆ
            if not self._answer_sent_in_loop:
                final_answer = "é”™è¯¯ï¼šAgent æ‰§è¡Œè¿‡ç¨‹ä¸­æœªç”Ÿæˆæœ‰æ•ˆå›å¤ã€è¯·æ£€æŸ¥ä»»åŠ¡é…ç½®æˆ–é‡è¯•ã€‚"
                for msg in reversed(self.agent.memory.messages):
                    if msg.role == "assistant" and msg.content:
                        final_answer = msg.content
                        break

                # ç”Ÿæˆ CLTP content(channel='plain', done=true) chunk
                # å…³é”®ï¼šä¿æŒæ–‡æœ¬å†…å®¹åŸæ ·ï¼Œä¸è¿›è¡Œä»»ä½•ä¿®æ”¹
                answer_chunk = self._cltp_generator.emit_content(
                    channel='plain',
                    payload={'text': final_answer},  # ä¿æŒåŸæ ·
                    done=True,
                )

                # Ensure fallback answer is stored for history persistence
                self._ensure_assistant_message(final_answer)

                yield AnswerEvent(
                    content=final_answer,
                    is_complete=True,
                    session_id=self._session_id,
                )

            # ä¿å­˜åˆ°å†å²è®°å½• - ä¿å­˜æ‰€æœ‰ç±»å‹çš„æ¶ˆæ¯ï¼ˆåŒ…æ‹¬ Tool æ¶ˆæ¯ï¼‰
            if self._chat_history_manager:
                # ä»…ä¿å­˜æœ¬æ¬¡æ‰§è¡Œè¿‡ç¨‹ä¸­æ–°å¢çš„æ¶ˆæ¯ï¼ˆé¿å…é‡å¤ä¿å­˜å†å²æ¶ˆæ¯ï¼‰
                new_messages = self.agent.memory.messages[start_memory_len:]

                deduped_messages = self._dedupe_messages(new_messages)

                for msg in deduped_messages:
                    if msg.role == Role.USER:
                        # ç”¨æˆ·æ¶ˆæ¯å·²åœ¨ stream.py ä¸­å†™å…¥ history
                        continue

                    # ä¿å­˜ assistant æ¶ˆæ¯ï¼ˆå¯èƒ½åŒ…å« tool_callsï¼‰
                    if msg.role == Role.ASSISTANT:
                        self._chat_history_manager.add_message(Message(
                            role=Role.ASSISTANT,
                            content=msg.content,
                            tool_calls=msg.tool_calls
                        ))
                    # ä¿å­˜ tool æ¶ˆæ¯ï¼ˆå…³é”®ï¼šåŒ…å« optimization_suggestions JSONï¼‰
                    elif msg.role == Role.TOOL:
                        self._chat_history_manager.add_message(Message(
                            role=Role.TOOL,
                            content=msg.content,
                            name=msg.name,
                            tool_call_id=msg.tool_call_id
                        ))
                        logger.debug(f"  ğŸ’¾ ä¿å­˜ Tool æ¶ˆæ¯: {msg.name}, é•¿åº¦: {len(msg.content or '')}")

                logger.info(
                    f"ğŸ“œ å·²ä¿å­˜å¯¹è¯åˆ° ChatHistory (æ–°å¢ {len(deduped_messages)} æ¡æ¶ˆæ¯, "
                    f"æ€»å†…å­˜ {len(self.agent.memory.messages)} æ¡)"
                )

            # Completed state
            await self._state_machine.transition_to(
                AgentState.COMPLETED,
                message="Agent execution completed",
            )

            # ç”Ÿæˆ CLTP span:end(name='run') chunk
            run_end_chunk = self._cltp_generator.emit_span_end('run')

            yield AgentEndEvent(
                agent_name="Manus",
                success=True,
                session_id=self._session_id,
            )

        except Exception as e:
            logger.exception(f"Error during agent execution: {e}")
            await self._state_machine.handle_error(e)
            if self._chat_history_manager:
                self._chat_history_manager.add_message(
                    Message.assistant_message(f"Agentè¿è¡Œå¤±è´¥ï¼š{str(e)}")
                )
            yield AgentErrorEvent(
                error_message=str(e),
                error_type=type(e).__name__,
                session_id=self._session_id,
            )

    async def send_event(self, event: StreamEvent) -> None:
        """Send an event to the client.

        Args:
            event: The event to send
        """
        try:
            task = self._send_event(event.to_dict())
            await asyncio.gather(task, return_exceptions=True)
        except Exception as e:
            logger.error(f"Error sending event: {e}")


class StreamProcessor:
    """Processes streaming agent output for multiple clients.

    Features:
    - Manage multiple active streams
    - Route events to correct clients
    - Handle stream lifecycle
    """

    def __init__(self) -> None:
        """Initialize the stream processor."""
        self._active_streams: dict[str, AgentStream] = {}
        self._lock = asyncio.Lock()

    async def start_stream(
        self,
        session_id: str,
        agent: Manus,
        state_machine: AgentStateMachine,
        event_sender: EventSender,
        user_message: str,
        chat_history_manager: Optional[Any] = None,
    ) -> AsyncIterator[StreamEvent]:
        """Start a new agent stream.

        Args:
            session_id: Unique session identifier
            agent: The Manus agent instance
            state_machine: The state machine for tracking
            event_sender: Function to send events
            user_message: The user's input
            chat_history_manager: Optional chat history manager

        Yields:
            StreamEvent instances during execution
        """
        stream = AgentStream(agent, session_id, state_machine, event_sender, chat_history_manager)

        async with self._lock:
            self._active_streams[session_id] = stream

        # Execute stream and yield events
        try:
            async for event in stream.execute(user_message):
                yield event
        finally:
            await self.remove_stream(session_id)

    async def remove_stream(self, session_id: str) -> None:
        """Remove a completed stream.

        Args:
            session_id: The session ID whose stream to remove
        """
        async with self._lock:
            self._active_streams.pop(session_id, None)

    def has_active_stream(self, session_id: str) -> bool:
        """Check if a session has an active stream.

        Args:
            session_id: The session ID to check

        Returns:
            True if stream is active
        """
        return session_id in self._active_streams

    def get_stream(self, session_id: str) -> Optional[AgentStream]:
        """Get an active stream.

        Args:
            session_id: The session ID

        Returns:
            The AgentStream if active, None otherwise
        """
        return self._active_streams.get(session_id)

    async def stop_stream(self, session_id: str) -> bool:
        """Request a stream to stop.

        Args:
            session_id: The session ID whose stream to stop

        Returns:
            True if stream was found and stop requested
        """
        stream = self.get_stream(session_id)
        if stream:
            stream._state_machine.request_stop()
            return True
        return False
