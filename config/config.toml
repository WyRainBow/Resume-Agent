# Global LLM configuration - DeepSeek
[llm]
model = "deepseek-chat"                      # DeepSeek 模型
base_url = "https://api.deepseek.com/v1"     # DeepSeek API 端点
api_key = "sk-bb444e462083474382b066c6e484bd0c"  # DeepSeek API Key
max_tokens = 8192                            # 最大 token 数
temperature = 0.0                            # 控制随机性

# Vision model (使用相同配置)
[llm.vision]
model = "deepseek-chat"
base_url = "https://api.deepseek.com/v1"
api_key = "sk-bb444e462083474382b066c6e484bd0c"
max_tokens = 8192
temperature = 0.0
